{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 16:22:31.274962: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-14 16:22:31.621668: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-14 16:22:31.624248: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-14 16:22:33.730590: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# import idx2numpy for extraction of image data (plus numpy and matplotlib)\n",
    "import idx2numpy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>ascii</th>\n",
       "      <th>char</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>53</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>54</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>55</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>56</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>65</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>66</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>67</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>68</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>69</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>70</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>71</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>72</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>73</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>74</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>75</td>\n",
       "      <td>K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>76</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>77</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>78</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>79</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>80</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>81</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>82</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>83</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>84</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>85</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>86</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>87</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>88</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>89</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>90</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>97</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>98</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>100</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>101</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>102</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>103</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>104</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>110</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>113</td>\n",
       "      <td>q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>114</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>116</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label  ascii char\n",
       "0       0     48    0\n",
       "1       1     49    1\n",
       "2       2     50    2\n",
       "3       3     51    3\n",
       "4       4     52    4\n",
       "5       5     53    5\n",
       "6       6     54    6\n",
       "7       7     55    7\n",
       "8       8     56    8\n",
       "9       9     57    9\n",
       "10     10     65    A\n",
       "11     11     66    B\n",
       "12     12     67    C\n",
       "13     13     68    D\n",
       "14     14     69    E\n",
       "15     15     70    F\n",
       "16     16     71    G\n",
       "17     17     72    H\n",
       "18     18     73    I\n",
       "19     19     74    J\n",
       "20     20     75    K\n",
       "21     21     76    L\n",
       "22     22     77    M\n",
       "23     23     78    N\n",
       "24     24     79    O\n",
       "25     25     80    P\n",
       "26     26     81    Q\n",
       "27     27     82    R\n",
       "28     28     83    S\n",
       "29     29     84    T\n",
       "30     30     85    U\n",
       "31     31     86    V\n",
       "32     32     87    W\n",
       "33     33     88    X\n",
       "34     34     89    Y\n",
       "35     35     90    Z\n",
       "36     36     97    a\n",
       "37     37     98    b\n",
       "38     38    100    d\n",
       "39     39    101    e\n",
       "40     40    102    f\n",
       "41     41    103    g\n",
       "42     42    104    h\n",
       "43     43    110    n\n",
       "44     44    113    q\n",
       "45     45    114    r\n",
       "46     46    116    t"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read mapping file as dataframe\n",
    "mapping = pd.read_csv(\"data/emnist-balanced-mapping.txt\", sep=\" \", header=None)\n",
    "mapping = mapping.rename(columns={0: \"label\", 1: \"ascii\"})\n",
    "\n",
    "#add \"translated\" label as \"char\" variable\n",
    "\"\"\"\n",
    "label is in data,\n",
    "ascii is the corresponding unicode code,\n",
    "char is the 'translation'\n",
    "\"\"\"\n",
    "mapping.loc[:, \"char\"] = mapping.ascii.apply(chr)\n",
    "\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use idx method convert_from_file() for extraction into array - separate for train and test\n",
    "train_img = idx2numpy.convert_from_file(\"data/emnist-balanced-train-images-idx3-ubyte\")\n",
    "test_img = idx2numpy.convert_from_file(\"data/emnist-balanced-test-images-idx3-ubyte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same for the labels files\n",
    "train_lab = idx2numpy.convert_from_file(\"data/emnist-balanced-train-labels-idx1-ubyte\")\n",
    "test_lab = idx2numpy.convert_from_file(\"data/emnist-balanced-test-labels-idx1-ubyte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize image data and reshape image data for the channels dimension\n",
    "train_img = np.reshape(train_img, (-1, 28, 28, 1)) / 255\n",
    "test_img = np.reshape(test_img, (-1, 28, 28, 1)) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transpose tilted image data\n",
    "train_img = np.transpose(train_img, (0, 2, 1, 3))\n",
    "test_img = np.transpose(test_img, (0, 2, 1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode the label data\n",
    "train_lab_enc = to_categorical(train_lab)\n",
    "test_lab_enc = to_categorical(test_lab)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up model via function\n",
    "def initialize_model():\n",
    "\n",
    "    model = models.Sequential()\n",
    "\n",
    "    ### First Convolution & MaxPooling\n",
    "    model.add(layers.Conv2D(8, (4,4), input_shape=(28,28,1), activation=\"relu\", padding=\"same\"))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(layers.Conv2D(64, (3,3), activation=\"relu\"))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(layers.Conv2D(32, (3,3), activation=\"relu\"))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    model.add(layers.Dense(47, activation=\"relu\"))\n",
    "    \n",
    "    model.add(layers.Dense(47, activation=\"softmax\"))\n",
    "    \n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = initialize_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 16:40:48.573840: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 282992640 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2820/2820 [==============================] - 52s 18ms/step - loss: 0.9353 - accuracy: 0.7138 - val_loss: 0.5601 - val_accuracy: 0.8167\n",
      "Epoch 2/100\n",
      "2820/2820 [==============================] - 50s 18ms/step - loss: 0.4951 - accuracy: 0.8322 - val_loss: 0.4668 - val_accuracy: 0.8373\n",
      "Epoch 3/100\n",
      "2820/2820 [==============================] - 49s 17ms/step - loss: 0.4276 - accuracy: 0.8509 - val_loss: 0.4272 - val_accuracy: 0.8479\n",
      "Epoch 4/100\n",
      "2820/2820 [==============================] - 50s 18ms/step - loss: 0.3900 - accuracy: 0.8623 - val_loss: 0.3923 - val_accuracy: 0.8597\n",
      "Epoch 5/100\n",
      "2820/2820 [==============================] - 50s 18ms/step - loss: 0.3662 - accuracy: 0.8697 - val_loss: 0.3843 - val_accuracy: 0.8618\n",
      "Epoch 6/100\n",
      "2820/2820 [==============================] - 50s 18ms/step - loss: 0.3459 - accuracy: 0.8760 - val_loss: 0.3902 - val_accuracy: 0.8615\n",
      "Epoch 7/100\n",
      "2820/2820 [==============================] - 51s 18ms/step - loss: 0.3333 - accuracy: 0.8789 - val_loss: 0.3698 - val_accuracy: 0.8673\n",
      "Epoch 8/100\n",
      "2820/2820 [==============================] - 49s 17ms/step - loss: 0.3184 - accuracy: 0.8826 - val_loss: 0.3687 - val_accuracy: 0.8667\n",
      "Epoch 9/100\n",
      "2820/2820 [==============================] - 50s 18ms/step - loss: 0.3084 - accuracy: 0.8863 - val_loss: 0.3772 - val_accuracy: 0.8655\n",
      "Epoch 10/100\n",
      "2820/2820 [==============================] - 50s 18ms/step - loss: 0.2983 - accuracy: 0.8883 - val_loss: 0.3719 - val_accuracy: 0.8689\n",
      "Epoch 11/100\n",
      "2820/2820 [==============================] - 49s 18ms/step - loss: 0.2887 - accuracy: 0.8934 - val_loss: 0.3763 - val_accuracy: 0.8693\n",
      "Epoch 12/100\n",
      "2820/2820 [==============================] - 51s 18ms/step - loss: 0.2816 - accuracy: 0.8930 - val_loss: 0.3660 - val_accuracy: 0.8711\n",
      "Epoch 13/100\n",
      "2820/2820 [==============================] - 51s 18ms/step - loss: 0.2740 - accuracy: 0.8965 - val_loss: 0.3766 - val_accuracy: 0.8702\n",
      "Epoch 14/100\n",
      "2820/2820 [==============================] - 51s 18ms/step - loss: 0.2668 - accuracy: 0.8986 - val_loss: 0.3765 - val_accuracy: 0.8716\n",
      "Epoch 15/100\n",
      "2820/2820 [==============================] - 52s 18ms/step - loss: 0.2606 - accuracy: 0.9014 - val_loss: 0.3882 - val_accuracy: 0.8660\n",
      "Epoch 16/100\n",
      "2820/2820 [==============================] - 52s 18ms/step - loss: 0.2568 - accuracy: 0.9010 - val_loss: 0.3797 - val_accuracy: 0.8686\n",
      "Epoch 17/100\n",
      "2820/2820 [==============================] - 51s 18ms/step - loss: 0.2490 - accuracy: 0.9038 - val_loss: 0.4043 - val_accuracy: 0.8652\n",
      "Epoch 18/100\n",
      "2820/2820 [==============================] - 50s 18ms/step - loss: 0.2447 - accuracy: 0.9049 - val_loss: 0.4036 - val_accuracy: 0.8636\n",
      "Epoch 19/100\n",
      "2820/2820 [==============================] - 54s 19ms/step - loss: 0.2389 - accuracy: 0.9059 - val_loss: 0.4066 - val_accuracy: 0.8621\n",
      "Epoch 20/100\n",
      "2820/2820 [==============================] - 53s 19ms/step - loss: 0.2356 - accuracy: 0.9074 - val_loss: 0.4000 - val_accuracy: 0.8668\n",
      "Epoch 21/100\n",
      "2820/2820 [==============================] - 52s 18ms/step - loss: 0.2321 - accuracy: 0.9087 - val_loss: 0.4101 - val_accuracy: 0.8677\n",
      "Epoch 22/100\n",
      "2820/2820 [==============================] - 52s 18ms/step - loss: 0.2262 - accuracy: 0.9104 - val_loss: 0.4244 - val_accuracy: 0.8650\n",
      "Epoch 23/100\n",
      "2820/2820 [==============================] - 52s 19ms/step - loss: 0.2234 - accuracy: 0.9116 - val_loss: 0.4279 - val_accuracy: 0.8654\n",
      "Epoch 24/100\n",
      "2820/2820 [==============================] - 52s 18ms/step - loss: 0.2201 - accuracy: 0.9123 - val_loss: 0.4407 - val_accuracy: 0.8652\n",
      "Epoch 25/100\n",
      "2820/2820 [==============================] - 52s 19ms/step - loss: 0.2148 - accuracy: 0.9140 - val_loss: 0.4309 - val_accuracy: 0.8629\n",
      "Epoch 26/100\n",
      "2820/2820 [==============================] - 52s 18ms/step - loss: 0.2126 - accuracy: 0.9142 - val_loss: 0.4807 - val_accuracy: 0.8555\n",
      "Epoch 27/100\n",
      "2820/2820 [==============================] - 52s 18ms/step - loss: 0.2110 - accuracy: 0.9143 - val_loss: 0.4402 - val_accuracy: 0.8627\n",
      "Epoch 28/100\n",
      "2820/2820 [==============================] - 52s 18ms/step - loss: 0.2077 - accuracy: 0.9158 - val_loss: 0.4580 - val_accuracy: 0.8613\n",
      "Epoch 29/100\n",
      "2820/2820 [==============================] - 52s 18ms/step - loss: 0.2025 - accuracy: 0.9182 - val_loss: 0.4501 - val_accuracy: 0.8595\n",
      "Epoch 30/100\n",
      "2820/2820 [==============================] - 52s 19ms/step - loss: 0.2008 - accuracy: 0.9188 - val_loss: 0.4695 - val_accuracy: 0.8586\n",
      "Epoch 31/100\n",
      "2820/2820 [==============================] - 53s 19ms/step - loss: 0.1987 - accuracy: 0.9184 - val_loss: 0.4693 - val_accuracy: 0.8585\n",
      "Epoch 32/100\n",
      "2820/2820 [==============================] - 45s 16ms/step - loss: 0.1972 - accuracy: 0.9185 - val_loss: 0.4855 - val_accuracy: 0.8591\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f8214e8d030>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = EarlyStopping(patience=20, restore_best_weights=True)\n",
    "\n",
    "mod.fit(train_img, train_lab_enc, validation_split=0.2, callbacks=[es], epochs=100, batch_size=32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting generated input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(file):\n",
    "    \"\"\"\n",
    "    load image from file, convert to grey scale and apply linear transformations + normalization\n",
    "    \"\"\"\n",
    "    img = Image.open(file) \n",
    "    img = img.convert(mode=\"L\") \n",
    "    img_arr = np.asarray(img) \n",
    "    img_arr = (img_arr * (-1) + 255) / 255 \n",
    "    img_arr = img_arr.reshape((1,28,28,1))\n",
    "    \n",
    "    return img_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(image_array, model=mod):\n",
    "    prediction = np.argmax(model.predict(image_array))\n",
    "    mapping = pd.read_csv(\"data/emnist-balanced-mapping.txt\", sep=\" \", header=None) #TO DO Pfad anpassen\n",
    "    mapping = mapping.rename(columns={0: \"label\", 1: \"ascii\"})\n",
    "    \n",
    "    return chr(mapping.loc[prediction, 'ascii'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "N\n"
     ]
    }
   ],
   "source": [
    "print(output(input_N, mod))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emnist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
